name: Garden Codex Maintenance

on:
  workflow_dispatch: {}

permissions:
  contents: write

jobs:
  codex-maintenance:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.x"

      - name: Fix Novellas, build indexes, manifest, monolith & API
        run: |
          python - << 'PY'
          import json
          from pathlib import Path
          from html import escape as h

          ROOT = Path(".").resolve()
          NOVELLAS_DIR = ROOT / "docs" / "Novellas"
          ARCHIVES_DIR = ROOT / "docs" / "Archives"
          API_DIR = ROOT / "docs" / "api"
          API_DIR.mkdir(parents=True, exist_ok=True)

          MD_INDEX_MD = ARCHIVES_DIR / "FULL_CODEX_INDEX.md"
          MD_INDEX_JSON = ARCHIVES_DIR / "FULL_CODEX_INDEX.json"
          MONOLITH_HTML = ARCHIVES_DIR / "CODEX_MONOLITH.html"
          MANIFEST_JSON = ARCHIVES_DIR / "GARDEN_MANIFEST.json"
          API_INDEX_JSON = API_DIR / "GARDEN_API_INDEX.json"

          # ---------- 1) Fix Novellas headings ----------

          def needs_heading(text: str) -> bool:
              for line in text.splitlines():
                  stripped = line.strip()
                  if not stripped:
                      continue
                  if stripped.startswith("#"):
                      heading = stripped.lstrip("#").strip().lower()
                      return not heading.startswith("book ")
                  else:
                      return True
              return True

          def make_heading(filename: str) -> str:
              if not filename.endswith(".md"):
                  return None
              name = filename[:-3]
              if not name.startswith("The_Garden_"):
                  return None
              rest = name[len("The_Garden_"):]
              if "_Book_" not in rest:
                  return None
              title_part, roman_part = rest.rsplit("_Book_", 1)
              roman = roman_part.upper()
              title_words = title_part.replace("_", " ")
              title = f"The Garden {title_words}"
              return f"# Book {roman} â€” {title}"

          if NOVELLAS_DIR.is_dir():
              for path in sorted(NOVELLAS_DIR.glob("The_Garden_*_Book_*.md")):
                  text = path.read_text(encoding="utf-8")
                  if not needs_heading(text):
                      print(f"[SKIP] {path}")
                      continue
                  heading = make_heading(path.name)
                  if not heading:
                      print(f"[WARN] Could not derive heading for {path}")
                      continue
                  new_text = heading + "\n\n" + text
                  path.write_text(new_text, encoding="utf-8")
                  print(f"[FIXED] Inserted heading in {path}")
          else:
              print(f"[WARN] Novellas dir not found at {NOVELLAS_DIR}")

          # ---------- 2) Build full codex index (all .md) ----------

          EXCLUDE_DIRS = {
              ".git", ".github", "node_modules", "dist",
              "machine", "scripts", ".well-known"
          }
          EXCLUDE_FILES = {"README.md", "README_GARDEN.md"}

          def is_excluded(p: Path) -> bool:
              rel = p.relative_to(ROOT)
              parts = rel.parts
              if parts and parts[0] in EXCLUDE_DIRS:
                  return True
              if rel.name in EXCLUDE_FILES:
                  return True
              return False

          md_entries = []
          for p in ROOT.rglob("*.md"):
              if is_excluded(p):
                  continue
              rel = p.relative_to(ROOT)
              md_entries.append(rel)

          sections = {}
          for rel in md_entries:
              top = rel.parts[0]
              sections.setdefault(top, []).append(rel)

          ARCHIVES_DIR.mkdir(parents=True, exist_ok=True)

          # Markdown index
          lines = []
          lines.append("# ðŸŒ³ Full Garden Codex Index")
          lines.append("")
          lines.append("_Automatically generated by garden_codex_maintenance.yml_")
          lines.append("")

          for top in sorted(sections):
              lines.append(f"## {top}")
              lines.append("")
              for rel in sorted(sections[top]):
                  lines.append(f"- `{rel}`")
              lines.append("")

          MD_INDEX_MD.write_text("\n".join(lines) + "\n", encoding="utf-8")
          print(f"[INDEX] Wrote full index â†’ {MD_INDEX_MD}")

          # JSON index
          json_entries = []
          for rel in md_entries:
              parts = rel.parts
              top = parts[0]
              json_entries.append({
                  "path": str(rel),
                  "top": top,
                  "name": rel.name,
              })

          MD_INDEX_JSON.write_text(
              json.dumps(json_entries, indent=2, ensure_ascii=False),
              encoding="utf-8"
          )
          print(f"[INDEX] Wrote JSON index â†’ {MD_INDEX_JSON}")

          # ---------- 3) Build Garden Manifest (all text-like files) & chunked Monolith ----------

          TEXT_EXTS = {
              ".md", ".txt", ".json", ".yml", ".yaml",
              ".js", ".ts", ".jsx", ".tsx",
              ".css", ".scss",
              ".html", ".htm",
              ".svg",
              ".py", ".sh", ".ps1",
              ".toml", ".ini", ".cfg",
              ".xml"
          }

          MONO_EXCLUDE_DIRS = EXCLUDE_DIRS | {".vscode", ".idea", ".gitmodules"}

          def mono_excluded(p: Path) -> bool:
              rel = p.relative_to(ROOT)
              parts = rel.parts
              if parts and parts[0] in MONO_EXCLUDE_DIRS:
                  return True
              return False

          text_files = []
          for p in ROOT.rglob("*"):
              if not p.is_file():
                  continue
              if mono_excluded(p):
                  continue
              if p.suffix.lower() in TEXT_EXTS:
                  text_files.append(p)

          text_files = sorted(text_files, key=lambda x: str(x.relative_to(ROOT)))

          # ---- 3a) Manifest JSON ----

          manifest_entries = []
          for p in text_files:
              rel = p.relative_to(ROOT)
              parts = rel.parts
              top = parts[0] if parts else ""
              category = ""
              if len(parts) >= 2 and parts[0] == "docs":
                  category = parts[1]
              manifest_entries.append({
                  "path": str(rel),
                  "top": top,
                  "category": category,
                  "name": rel.name,
                  "ext": p.suffix.lower(),
                  "size_bytes": p.stat().st_size,
              })

          MANIFEST_JSON.write_text(
              json.dumps(manifest_entries, indent=2, ensure_ascii=False),
              encoding="utf-8"
          )
          print(f"[MANIFEST] Wrote â†’ {MANIFEST_JSON}")

          # ---- 3b) Chunked Monolith HTML ----

          def make_page_html(title: str, sections_html: str) -> str:
              head = []
              head.append("<!DOCTYPE html>")
              head.append("<html lang='en'><head>")
              head.append("<meta charset='utf-8'/>")
              head.append(f"<title>{h(title)}</title>")
              head.append("<style>")
              head.append("body{background:#050812;color:#f5f5f5;font-family:system-ui,monospace;font-size:14px;}")
              head.append("h1,h2,h3{font-family:system-ui,sans-serif;}")
              head.append("section{margin:24px 12px;border-top:1px solid #222;padding-top:16px;}")
              head.append("pre{white-space:pre-wrap;word-break:break-word;background:#050b16;padding:12px;border-radius:8px;}")
              head.append(".path{color:#88f;font-size:13px;margin-bottom:4px;}")
              head.append("a{color:#8af;}")
              head.append("</style></head><body>")
              head.append(f"<h1>{h(title)}</h1>")
              return "\n".join(head) + "\n" + sections_html + "\n</body></html>"

          CHUNK_CHAR_TARGET = 300_000

          chunk_files = []  # list of (chunk_name, [paths_in_chunk])
          chunk_idx = 1
          current_sections = []
          current_paths = []
          current_len = 0

          def flush_chunk():
              global chunk_idx, current_sections, current_paths, current_len
              if not current_sections:
                  return
              chunk_name = f"CODEX_MONOLITH_CHUNK_{chunk_idx:03}.html"
              chunk_path = ARCHIVES_DIR / chunk_name
              page_html = make_page_html(
                  f"ACACIA Â· GARDEN Â· CODEX Â· MONOLITH Â· CHUNK {chunk_idx:03}",
                  "\n".join(current_sections)
              )
              chunk_path.write_text(page_html, encoding="utf-8")
              print(f"[MONOLITH] Wrote chunk {chunk_idx:03} â†’ {chunk_path}")
              chunk_files.append((chunk_name, [str(p) for p in current_paths]))
              chunk_idx += 1
              current_sections = []
              current_paths = []
              current_len = 0

          for path in text_files:
              rel = path.relative_to(ROOT)
              try:
                  text = path.read_text(encoding="utf-8", errors="replace")
              except Exception as e:
                  print(f"[MONO-SKIP] {rel}: {e}")
                  continue

              section_parts = []
              section_parts.append("<section>")
              section_parts.append(f"<h2 id='{h(str(rel)).replace('/', '_')}'>{h(str(rel))}</h2>")
              section_parts.append(f"<div class='path'>Path: {h(str(rel))}</div>")
              section_parts.append("<pre>")
              section_parts.append(h(text))
              section_parts.append("</pre>")
              section_parts.append("</section>")
              section_html = "\n".join(section_parts)

              if current_sections and (current_len + len(section_html) > CHUNK_CHAR_TARGET):
                  flush_chunk()

              current_sections.append(section_html)
              current_paths.append(rel)
              current_len += len(section_html)

          flush_chunk()

          # ---- 3c) Monolith Index HTML ----

          index_sections = []
          index_sections.append("<p>This is a tool-friendly index of the full Garden Monolith.</p>")
          index_sections.append("<p>All text-like files are included across the chunked pages below.</p>")
          index_sections.append("<ul>")
          total_files = 0
          for chunk_name, paths in chunk_files:
              total_files += len(paths)
              index_sections.append("<li>")
              index_sections.append(f"<a href='{h(chunk_name)}'>{h(chunk_name)}</a>")
              index_sections.append(f" â€” {len(paths)} files")
              index_sections.append("</li>")
          index_sections.append("</ul>")
          index_sections.append(f"<p>Total files included: {total_files}</p>")
          index_sections.append("<p>See also: <code>docs/Archives/GARDEN_MANIFEST.json</code> and <code>docs/api/GARDEN_API_INDEX.json</code>.</p>")

          MONOLITH_HTML.write_text(
              make_page_html(
                  "ACACIA Â· GARDEN Â· CODEX Â· MONOLITH Â· INDEX",
                  "\n".join(index_sections)
              ),
              encoding="utf-8"
          )
          print(f"[MONOLITH] Wrote index â†’ {MONOLITH_HTML}")

          # ---------- 4) Garden API index ----------

          api_index = {
              "manifest": "docs/Archives/GARDEN_MANIFEST.json",
              "monolith_index": "docs/Archives/CODEX_MONOLITH.html",
              "monolith_chunks": [
                  {
                      "file": chunk_name,
                      "paths": paths
                  }
                  for chunk_name, paths in chunk_files
              ]
          }

          API_INDEX_JSON.write_text(
              json.dumps(api_index, indent=2, ensure_ascii=False),
              encoding="utf-8"
          )
          print(f"[API] Wrote API index â†’ {API_INDEX_JSON}")
          PY

      - name: Commit and push changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: update codex indexes, manifest, monolith & API"
          branch: ${{ github.ref_name }}
