from __future__ import annotations

import json
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Any

from .config import KEEPER_ID
from .language_worker import run_language_job

# Directories
JOBS_DIR = Path("garden_gpt/jobs")
DONE_DIR = Path("garden_gpt/jobs_done")
OUTPUTS_DIR = Path("garden_gpt/outputs")


def _load_json(path: Path) -> Dict[str, Any]:
    """Safe JSON loader. Returns {} on any error."""
    try:
        text = path.read_text(encoding="utf-8")
        return json.loads(text)
    except Exception as exc:  # noqa: BLE001
        print(f"[Garden GPT] Failed to read job {path}: {exc}")
        return {}


def _ensure_dirs() -> None:
    JOBS_DIR.mkdir(parents=True, exist_ok=True)
    DONE_DIR.mkdir(parents=True, exist_ok=True)
    OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)


def _render_language_markdown(job_id: str, keeper: str, prompt: str, response: str) -> str:
    """Pretty markdown output for a language job."""
    ts = datetime.now(timezone.utc).isoformat()

    lines = [
        "# GARDEN GPT OUTPUT",
        "",
        f"**Job ID:** `{job_id}`  ",
        f"**Kind:** `language`  ",
        f"**Keeper:** `{keeper}`  ",
        f"**Generated:** `{ts}`",
        "",
        "---",
        "",
        "## Prompt",
        "",
        prompt.strip(),
        "",
        "---",
        "",
        "## Response",
        "",
        response.strip() or "_(no content returned)_",
        "",
        "> Note: Generated by Garden GPT Worker via GitHub Actions.",
        "",
    ]
    return "\n".join(lines)


def _process_language_job(job: Dict[str, Any], job_path: Path) -> None:
    """Handle a single language job and write markdown output."""
    job_id = job.get("job_id") or job.get("id") or job_path.stem
    prompt = (job.get("prompt") or "").strip()
    if not prompt:
        raise ValueError(f"Language job {job_id!r} is missing 'prompt' text.")

    keeper = job.get("keeper_id") or KEEPER_ID

    print(f"[Garden GPT] Running language job {job_id!r} for Keeper {keeper}...")

    # Call the worker (this hits the OpenAI API)
    response_text = run_language_job(job)

    # Write nice markdown output
    OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)
    out_path = OUTPUTS_DIR / f"{job_id}.md"
    out_path.write_text(
        _render_language_markdown(job_id, keeper, prompt, response_text),
        encoding="utf-8",
    )

    print(f"[Garden GPT] Wrote output to {out_path}")


def _move_to_done(job_path: Path) -> None:
    """Move processed job into jobs_done so it won't run again."""
    try:
        DONE_DIR.mkdir(parents=True, exist_ok=True)
        target = DONE_DIR / job_path.name
        job_path.rename(target)
        print(f"[Garden GPT] Moved job to {target}")
    except Exception as exc:  # noqa: BLE001
        print(f"[Garden GPT] WARNING: Could not move job {job_path}: {exc}")


def main() -> None:
    _ensure_dirs()

    job_files = sorted(JOBS_DIR.glob("*.json"))
    if not job_files:
        print("[Garden GPT] No jobs found in garden_gpt/jobs. Nothing to do.")
        return

    print(f"[Garden GPT] Found {len(job_files)} job(s).")

    for job_file in job_files:
        print(f"[Garden GPT] Processing job file {job_file}...")
        job = _load_json(job_file)
        if not job:
            print(f"[Garden GPT] Skipping empty/bad job file {job_file}.")
            continue

        kind = (job.get("kind") or "language").strip().lower()

        try:
            if kind == "language":
                _process_language_job(job, job_file)
            else:
                print(f"[Garden GPT] Unknown job kind {kind!r} in {job_file}, skipping.")
                continue
        except Exception as exc:  # noqa: BLE001
            print(f"[Garden GPT] ERROR while processing {job_file}: {exc}")
            continue

        # Only move if it succeeded
        _move_to_done(job_file)

    print("[Garden GPT] Queue processing complete.")


if __name__ == "__main__":
    main()
